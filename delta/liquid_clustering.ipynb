{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Enable/Disable",
   "id": "a55811075e44eb9a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "-- Create an empty table.\n",
    "CREATE OR REPLACE TABLE table1(column01 int, column02 string) CLUSTER BY AUTO;\n",
    "\n",
    "-- Enable automatic liquid clustering on an existing table,\n",
    "-- including tables that previously had manually specified keys.\n",
    "ALTER TABLE table1 CLUSTER BY AUTO;\n",
    "\n",
    "-- Disable automatic liquid clustering on an existing table.\n",
    "ALTER TABLE table1 CLUSTER BY NONE;\n",
    "\n",
    "-- Disable automatic liquid clustering by setting the clustering keys\n",
    "-- to chosen clustering columns or new columns.\n",
    "ALTER TABLE table1 CLUSTER BY (column01, column02);"
   ],
   "id": "1d4d0822c393332d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.read.table(\"table1\")\n",
    "\n",
    "df.write.format(\"delta\").option(\"clusterByAuto\", \"true\").saveAsTable(...)\n",
    "\n",
    "# To set clustering columns and auto, which serves as a way to give a hint\n",
    "# for the initial selection.\n",
    "df.write.format(\"delta\").clusterBy(\"clusteringColumn1\", \"clusteringColumn2\").option(\"clusterByAuto\",\n",
    "                                                                                    \"true\").saveAsTable(...)\n",
    "\n",
    "# Using DataFrameWriterV2\n",
    "df.writeTo(...).using(\"delta\").option(\"clusterByAuto\", \"true\").create()\n",
    "\n",
    "# To set clustering columns and auto, which serves as a way to give a hint\n",
    "# for the initial selection.\n",
    "df.writeTo(...).using(\"delta\").clusterBy(\"clusteringColumn1\", \"clusteringColumn2\").option(\"clusterByAuto\",\n",
    "                                                                                          \"true\").create()\n",
    "\n",
    "# Similar syntax can also be used to set clusterByAuto for streaming tables.\n",
    "spark.readStream.table(\"source_table\").writeStream.option(\"clusterByAuto\", \"true\").option(\"checkpointLocation\", checkpointPath).toTable(\"target_table\")\n",
    "\n",
    "# Or to specify a hint for the clustering columns by specifying both auto and columns together\n",
    "spark.readStream.table(\"source_table\").writeStream.clusterBy(\"column1\", \"column2\").option(\"clusterByAuto\", \"true\").option(\"checkpointLocation\", checkpointPath).toTable(\"target_table\")"
   ],
   "id": "13e78805f1e6f685"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Liquid Clustering Overview\n",
    "\n",
    "This notebook demonstrates various ways to work with liquid clustering in Delta tables."
   ],
   "id": "5d4daf5f41843d3a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Table Creation Methods\n",
    "The following sections show different approaches to create tables with clustering."
   ],
   "id": "18d3576587795791"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 SQL Approach",
   "id": "7404ee319b5f5b1f"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "-- Basic table creation with clustering\n",
    "CREATE TABLE table1(col0 INT, col1 string) CLUSTER BY (col0);\n",
    "\n",
    "-- CTAS with clustering\n",
    "CREATE EXTERNAL TABLE table2 CLUSTER BY (col0)\n",
    "LOCATION 'table_location'\n",
    "AS SELECT * FROM table1;\n",
    "\n",
    "-- Copy table structure\n",
    "CREATE TABLE table3 LIKE table1;\n",
    "\n",
    "-- view describe\n",
    "DESCRIBE TABLE table_name;\n",
    "\n",
    "DESCRIBE DETAIL table_name;"
   ],
   "id": "f43d987a2d70b421"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Python API Approach",
   "id": "e36cf2e028958dfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create table using DeltaTable API\n",
    "(DeltaTable.create()\n",
    " .tableName(\"table1\")\n",
    " .addColumn(\"col0\", dataType=\"INT\")\n",
    " .addColumn(\"col1\", dataType=\"STRING\")\n",
    " .clusterBy(\"col0\")\n",
    " .execute())\n",
    "\n",
    "# CTAS using DataFrameWriter\n",
    "df = spark.read.table(\"table1\")\n",
    "df.write.clusterBy(\"col0\").saveAsTable(\"table2\")\n",
    "\n",
    "# CTAS using DataFrameWriterV2\n",
    "df = spark.read.table(\"table1\")\n",
    "df.writeTo(\"table1\").using(\"delta\").clusterBy(\"col0\").create()"
   ],
   "id": "5bce0ab4a08f5cad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Table Alterations",
   "id": "26bad36eb9799927"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "ALTER TABLE <table_name>\n",
    "CLUSTER BY (<clustering_columns>)"
   ],
   "id": "5b9bde5986aa8795"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Streaming with Clustering",
   "id": "e1d77b1da3206922"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "CREATE TABLE table1 (\n",
    "  col0 STRING,\n",
    "  col1 DATE,\n",
    "  col2 BIGINT\n",
    ")\n",
    "CLUSTER BY (col0, col1)\n",
    "TBLPROPERTIES (\n",
    "  'clusterByAuto' = 'true'\n",
    ");"
   ],
   "id": "f7964b0dc3968c22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "(spark.readStream.table(\"source_table\")\n",
    " .writeStream\n",
    " .clusterBy(\"column_name\")\n",
    " .option(\"checkpointLocation\", checkpointPath)\n",
    " .toTable(\"target_table\"))"
   ],
   "id": "50d96fe4687986f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Auto-Clustering Management",
   "id": "d65973b0bca58739"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "-- Create auto-clustered table\n",
    "CREATE OR REPLACE TABLE table1(column01 int, column02 string) CLUSTER BY AUTO;\n",
    "\n",
    "-- Enable auto-clustering\n",
    "ALTER TABLE table1 CLUSTER BY AUTO;\n",
    "\n",
    "-- Disable clustering\n",
    "ALTER TABLE table1 CLUSTER BY NONE;\n",
    "\n",
    "-- Manual clustering columns\n",
    "ALTER TABLE table1 CLUSTER BY (column01, column02);"
   ],
   "id": "8ba9c51b0bd85467"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Auto-clustering with DataFrame API\n",
    "df = spark.read.table(\"table1\")\n",
    "\n",
    "df.write.format(\"delta\").option(\"clusterByAuto\", \"true\").saveAsTable(\"table_name\")\n",
    "\n",
    "# Hybrid approach with column hints\n",
    "df.write.format(\"delta\") \\\n",
    "    .clusterBy(\"clusteringColumn1\", \"clusteringColumn2\") \\\n",
    "    .option(\"clusterByAuto\", \"true\") \\\n",
    "    .saveAsTable(\"table_name\")\n",
    "\n",
    "# Using DataFrameWriterV2\n",
    "df.writeTo(\"table_name\").using(\"delta\").option(\"clusterByAuto\", \"true\").create()\n",
    "\n",
    "# Streaming with auto-clustering\n",
    "(spark.readStream.table(\"source_table\")\n",
    " .writeStream\n",
    " .option(\"clusterByAuto\", \"true\")\n",
    " .option(\"checkpointLocation\", checkpointPath)\n",
    " .toTable(\"target_table\"))\n",
    "\n",
    "# Streaming with column hints\n",
    "(spark.readStream.table(\"source_table\")\n",
    " .writeStream\n",
    " .clusterBy(\"column1\", \"column2\")\n",
    " .option(\"clusterByAuto\", \"true\")\n",
    " .option(\"checkpointLocation\", checkpointPath)\n",
    " .toTable(\"target_table\"))\n"
   ],
   "id": "2598ce8ca8627115"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Trigger",
   "id": "922b28b364722b91"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "OPTIMIZE table_name;\n",
    "OPTIMIZE table_name FULL; --16.0, large table not previously can take hours"
   ],
   "id": "37effb324f2cae09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
